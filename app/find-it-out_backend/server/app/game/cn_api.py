import csv
import json
import random
from os import path
from typing import List

import eventlet
import requests
import scipy.stats as st
import spacy
from nltk.corpus import wordnet as wn
from numpy import random as rd

from server.app.game.card import Card
from server.app.game.utils import clip

"""
This work includes data from ConceptNet 5, which was compiled by the Commonsense Computing Initiative.
ConceptNet 5 is freely available under the Creative Commons Attribution-ShareAlike license (CC BY SA 4.0) from 
https://conceptnet.io. The included data was created by contributors to Commonsense Computing projects, contributors to 
Wikimedia projects, Games with a Purpose, Princeton University's WordNet, DBPedia, OpenCyc, and Umbel.
"""


class ConceptNet:
    _nlp = None
    _concreteness_dict: dict = None

    # higher means more cards being generated by game before choosing
    # default = 1
    EXTRA_CARDS_FACTOR = 3

    # higher means tighter normal distribution (sigma = # of elements / DIFFICULTY_RANGE)
    # default = 3
    DIFFICULTY_RANGE = 6

    # how many words to search for
    SEARCH_LIMIT = 100

    # enforce how deep to search
    SEARCH_DEPTH = 3

    # conceptnet 5 language
    LANGUAGE = 'en'

    @staticmethod
    def generate_game(seed_word, difficulty) -> List[Card]:
        related = ConceptNet.generate_related(seed_word, difficulty.num_cards)

        chosen_words = ConceptNet._choose_n(related, difficulty.num_cards, 1 - difficulty.center)

        return chosen_words.tolist()

    @staticmethod
    def generate_related(seed_word, num_cards):
        prefix = f"/c/{ConceptNet.LANGUAGE}/"
        params = f"?filter=/c/{ConceptNet.LANGUAGE}&limit={ConceptNet.SEARCH_LIMIT}"
        # TODO save an "expanded" set so that we don't expand words already expanded
        found = set()
        result = []
        depth = 0
        result.append({'@id': seed_word, 'weight': 1})
        found.add(seed_word)

        while depth < ConceptNet.SEARCH_DEPTH or len(result) < num_cards * ConceptNet.EXTRA_CARDS_FACTOR:
            seed_word, weight = random.choice(result).values()
            obj = ConceptNet._fetch_related(term=f"{prefix}{seed_word}", pars=params)
            related = ConceptNet._simplify_names(obj['related'], prefix=prefix, weight=weight)
            # related_filtered_spacy = self._filter_nouns_spacy_nlp(related)
            related_filtered_wn = ConceptNet._filter_nouns_nltk_wn(related)
            related_filtered = ConceptNet._filter_concreteness(related_filtered_wn)
            new_words = [x for x in related_filtered if x['@id'] not in found]
            found.update(set([n['@id'] for n in new_words]))
            result.extend(new_words)
            depth += 1

            eventlet.sleep()

        return [Card(word) for word in result]

    @staticmethod
    def print_items(objs):
        print("The selected items are:")
        for idx, item in enumerate(objs):
            print(str(idx) + ". " + item['@id'])

    @staticmethod
    def _get_names(objs):
        return [item['@id'].replace('/c/en/', '') for item in objs]

    @staticmethod
    def _simplify_names(objs, prefix, weight):
        for item in objs:
            item['@id'] = item['@id'].replace(prefix, '')
            item['weight'] *= weight
        return objs

    @staticmethod
    def _get_distribution(loc, size):
        norm = st.norm(loc * size, size / ConceptNet.DIFFICULTY_RANGE)
        probs = [norm.pdf(n) for n in range(size)]
        s = sum(probs)
        return [item / s for item in probs]

    @staticmethod
    def _get_word_types(objs):
        """
        Uses Spacy NLP to determine the word type (noun, verb, etc.)
        :param objs: objects to augment
        :return: list describing word type of given word list
        """
        if ConceptNet.nlp is None:
            ConceptNet.nlp = spacy.load("en_core_web_sm")
        return [ConceptNet._nlp(item['@id'])[0].pos_ for item in objs]

    @staticmethod
    def _filter_nouns_spacy_nlp(objs):
        types = ConceptNet._get_word_types(objs)
        return [item for idx, item in enumerate(objs) if types[idx] == 'NOUN']

    @staticmethod
    def _filter_nouns_nltk_wn(objs):
        """
        Uses NLTK WordNet to determine the word type (noun, verb, etc.)
        :param objs: objects to filter
        :return: filtered
        """
        pos_all = dict()
        for w in objs:
            pos_l = set()
            for tmp in wn.synsets(w['@id']):
                if tmp.name().split('.')[0] == w['@id']:
                    pos_l.add(tmp.pos())
            pos_all[w['@id']] = pos_l
        return [item for item in objs if 'n' in pos_all[item['@id']]]

    @staticmethod
    def _fetch_related(term, pars):
        import os
        file_path = f"{os.path.abspath(os.path.dirname(__file__))}/cn_requests/{term.replace('/c/en/', '')}.json"

        if path.exists(file_path):
            with open(file_path) as f:
                res = json.load(f)
        else:
            res: dict = requests.get('https://api.conceptnet.io/related' + term + pars).json()
            with open(file_path, 'w') as json_file:
                json.dump(res, json_file)

        return res

    @staticmethod
    def _choose_n(objs: List[Card], n, loc):
        """
        Chooses n items from the objs list using a normal distribution at loc = [0,1] location.
        """
        sorted_objs = [v for v in sorted(objs, key=lambda item: item.weight, reverse=True)]
        return rd.choice(a=sorted_objs, size=n, replace=False,
                         p=ConceptNet._get_distribution(clip(loc, 0, 1), len(objs)))

    @staticmethod
    def _load_word_dic() -> dict:
        concreteness = dict()
        import os
        with open(f"{os.path.abspath(os.path.dirname(__file__))}/resources/reduced_concreteness.csv") as f:
            reader = csv.DictReader(f, fieldnames=(
                # 'word', 'is_bigram', 'concr_mean', 'concre_sd', 'n_people_unknown', 'n_people_total',
                # 'percent_known', 'subtlex', 'dom_pos'
                'word', 'concr_mean', 'concr_sd'
            ))
            for row in reader:
                concreteness[row['word']] = row
        return concreteness

    @staticmethod
    def _filter_concreteness(objs):
        if ConceptNet._concreteness_dict is None:
            ConceptNet._concreteness_dict = ConceptNet._load_word_dic()
        return [item for item in objs if
                not item['@id'] in ConceptNet._concreteness_dict.keys()
                or float(ConceptNet._concreteness_dict[item['@id']]['concr_mean']) >= 4]

# Shows graph of weights of terms
# sns.lineplot(data=[item['weight'] for item in obj['related']])
# sns.lineplot(data=get_distribution(0, len(obj['related'])))
# plt.show()

# checking concrete nouns
# from nltk.corpus import wordnet as wn

# wn.synsets('chair')
# wn.synset('chair.n.01').hypernyms()
# wn.synset('chair.n.01').root_hypernyms()
# [Synset('emotion.n.01')]

# import nltk
# nltk.download('wordnet')
# nltk.download('averaged_perceptron_tagger')
#
# # taking input text as India
# text = "India"
# ans = nltk.pos_tag()
#
# # ans returns a list of tuple
# val = ans[0][1]
#
# # checking if it is a noun or not
# if (val == 'NN' or val == 'NNS' or val == 'NNPS' or val == 'NNP'):
#     print(text, " is a noun.")
# else:
#     print(text, " is not a noun.")
